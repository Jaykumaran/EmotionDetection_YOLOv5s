{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Face Emotion Detection Yolo**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Install YOLOv8**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5','yolov5s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = 'https://ultralytics.com/images/zidane.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results  = model(img)\n",
    "results.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.imshow(np.squeeze(results.render()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.squeeze(results.render()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd C:/Users/jaikr/Downloads/CV_Projs/Face Emotion Detection/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Webcam realtime Detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "  ret, frame = cap.read()\n",
    "\n",
    "\n",
    "  results = model(frame)\n",
    "\n",
    "  cv2.imshow('Emotion Detection',np.squeeze(results.render()))\n",
    "\n",
    "  if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "    break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "      \n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Custom class Detection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid   #unique identifier\n",
    "import os \n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install uuid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_PATH = os.path.join('data','images')  #data/images\n",
    "labels = ['Neutral','Drowsy','Headache','Sad','Happy','Self harm','Angry','Surprised','Thinking']\n",
    "number_imgs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# Loop through labels\n",
    "for label in labels:\n",
    "    print('Collecting images for {}'.format(label))\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # Loop through image range\n",
    "    for img_num in range(number_imgs):\n",
    "        print('Collecting images for {}, image number {}'.format(label, img_num))\n",
    "        \n",
    "        # Webcam feed\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Naming out image path\n",
    "        imgname = os.path.join(IMAGES_PATH, label+'.'+str(uuid.uuid1())+'.jpg')\n",
    "        \n",
    "        # Writes out image to file \n",
    "        cv2.imwrite(imgname, frame)\n",
    "        \n",
    "        # Render to the screen\n",
    "        cv2.imshow('Image Collection', frame)\n",
    "        \n",
    "        # 2 second delay between captures\n",
    "        time.sleep(2)\n",
    "        \n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgname = os.path.join(IMAGES_PATH,label+'.'+str(uuid.uuid1())+'.jpg')\n",
    "imgname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LABEL IMG for Annotation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/tzutalin/labelImg\n",
    "!pip install pyqt5 lxml --upgrade\n",
    "!cd labelImg && pyrcc5 -o libs/resources.py resources.qrc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRAINING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd yolov5 && python train.py --img 320 --batch 16 --epochs 500 --data dataset.yaml --weights yolov5s.pt --workers 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD CUSTOM MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5','custom',path='C:/Users/jaikr/Downloads/CV_Projs/Face Emotion Detection/yolov5/runs/train/exp/weights/last.pt',force_reload=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test with Train Img "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = os.path.join('data','images','C:/Users/jaikr/Downloads/CV_Projs/Face Emotion Detection/data/test/.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model(img)\n",
    "results.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.imshow(np.squeeze(results.render()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**REALTIME DETECTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "  ret, frame = cap.read()\n",
    "\n",
    "\n",
    "  results = model(frame)\n",
    "\n",
    "  cv2.imshow('Emotion Detection',np.squeeze(results.render()))\n",
    "\n",
    "  if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "    break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "      \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Change directory to yolov5\n",
    "os.chdir('yolov5')\n",
    "\n",
    "# Run inference\n",
    "command = r'python detect.py --source C:\\\\Users\\\\jaikr\\\\Downloads\\\\CV_Projs\\\\Face Emotion Detection\\\\data\\\\test --weights ../best.pt --save-txt --conf 0.5'\n",
    "os.system(command)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FaceEmotionDetection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
